{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('f1_visa_interview')"
  },
  "interpreter": {
   "hash": "7319741835937c9a7ccb71e0c1799b3e850519b7bf6441da0617d4324770e27d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       sender_id                                            message\n",
       "0 -1001285729190  My Visa experience - 07/08/2021\\nApproved✅\\nDe...\n",
       "1 -1001285729190  9th July 2021\\nLocation: Hyderabad\\nAppointmen...\n",
       "2 -1001285729190  July 9th\\nHyderabad Consulate\\nIn time 10:25\\n...\n",
       "3 -1001285729190  9th July 2021\\nChennai VAC(July 4) and VI\\nApp...\n",
       "4 -1001285729190  Visa experience - 8/7/21 \\nApproved✅\\nMumbai c..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sender_id</th>\n      <th>message</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1001285729190</td>\n      <td>My Visa experience - 07/08/2021\\nApproved✅\\nDe...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-1001285729190</td>\n      <td>9th July 2021\\nLocation: Hyderabad\\nAppointmen...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1001285729190</td>\n      <td>July 9th\\nHyderabad Consulate\\nIn time 10:25\\n...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1001285729190</td>\n      <td>9th July 2021\\nChennai VAC(July 4) and VI\\nApp...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1001285729190</td>\n      <td>Visa experience - 8/7/21 \\nApproved✅\\nMumbai c...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df = pd.read_csv('Messages_text.csv')\n",
    "df.head()"
   ]
  },
  {
   "source": [
    "## Exploring messages\n",
    "\n",
    "* Its possible that we have empty cells and some jargon messages where the len of the message is < 145 characters.\n",
    "* Note: 145 is not a magic number. After observing messages where the character size < 145, i concluded that the information available was irrelavent. Hence the messages with < 145 characters are ignored. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2397, 2)\nShape of dataframe after dropping nan rows\n(2357, 2)\n"
     ]
    }
   ],
   "source": [
    "# Check for Nan values in messages column.\n",
    "df['message'].isnull().sum()\n",
    "print(df.shape) # (2397, 2)\n",
    "# As there are 40 null values, we can drop the rows as they are of no use\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "print(\"Shape of dataframe after dropping nan rows\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MESSAGES_LEN_TO_IGNORE = 145\n",
    "\n",
    "df['length_of_message'] = df['message'].apply(lambda x : len(str(x)))\n",
    "# Filter out of the rows with message length < 145\n",
    "df_filter = df[df['length_of_message'] > MESSAGES_LEN_TO_IGNORE]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2301, 3)\n"
     ]
    }
   ],
   "source": [
    "# The final dataframe after filtering out un-necessary messages \n",
    "print(df_filter.shape)"
   ]
  },
  {
   "source": [
    "## Below attributes will be extracted from messages\n",
    "* [Extracting Status](#extract_status)\n",
    "* [Extracting Visa Interview Date](#extract_interview_date)\n",
    "* [Extracting location](#extract_location)\n",
    "* [Extracting Questions asked in VI](#extract_questions)\n",
    "* [Extracting University Name](#extract_university)\n",
    "* ~~Duration~~\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Extracting location\n",
    "<a id='extract_location'></a>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/ubuntu/repos/f1_visa_interview/lib/python3.8/site-packages/pandas/core/frame.py:3607: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._set_item(key, value)\n"
     ]
    }
   ],
   "source": [
    "def get_consulate_location(str_to_check):\n",
    "    known_consulate_locations = ['hyderabad', 'mumbai', 'kolkata', 'delhi', 'chennai', 'hyd', 'bombay', 'malaysia', 'madras']\n",
    "    str_converted_to_lower = str_to_check.lower()\n",
    "    for consulate_location in known_consulate_locations:\n",
    "        if consulate_location in str_converted_to_lower:\n",
    "            return consulate_location\n",
    "\n",
    "\n",
    "df_filter['consulate_location'] = df_filter['message'].apply(get_consulate_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/ubuntu/repos/f1_visa_interview/lib/python3.8/site-packages/pandas/core/generic.py:6383: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  return self._update_inplace(result)\n"
     ]
    }
   ],
   "source": [
    "mapping_dict = {'bombay' : \"mumbai\", 'hyd' : \"hyderabad\", \"madras\" : \"chennai\"}\n",
    "df_filter['consulate_location'] = df_filter['consulate_location'].apply(lambda x : mapping_dict.get(x) if mapping_dict.get(x) is not None else x )\n",
    "df_filter['consulate_location'].fillna(\"NA\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mumbai       912\ndelhi        534\nchennai      340\nhyderabad    302\nkolkata      158\nNA            54\nmalaysia       1\nName: consulate_location, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_filter.consulate_location.value_counts())\n",
    "df_filter.to_csv(\"Test.csv\", index=False)"
   ]
  },
  {
   "source": [
    "### Extracting Status \n",
    "<a id='extract_status'></a>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_visa_status(message):\n",
    "    possible_status = ['approved', 'rejected']\n",
    "    for _status in possible_status:\n",
    "        if _status in message.lower():\n",
    "            return _status\n",
    "\n",
    "df_filter['visa_status'] = df_filter['message'].apply(get_visa_status)\n",
    "df_filter['visa_status'].fillna(\"NA\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "approved    2027\n",
       "rejected     200\n",
       "NA            74\n",
       "Name: visa_status, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "df_filter['visa_status'].value_counts()"
   ]
  },
  {
   "source": [
    "### Extracting Questions\n",
    "<a id='extract_questions'></a>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/ubuntu/repos/f1_visa_interview/lib/python3.8/site-packages/pandas/core/frame.py:3607: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._set_item(key, value)\n/home/ubuntu/repos/f1_visa_interview/lib/python3.8/site-packages/pandas/core/generic.py:6383: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  return self._update_inplace(result)\n"
     ]
    }
   ],
   "source": [
    "questions_start_with = ['what', 'what\\'s', 'which', 'who', 'where', 'why', 'when', 'how', 'whose', 'do', 'are', 'will', 'did ']\n",
    "\n",
    "import re\n",
    "import string \n",
    "\n",
    "\n",
    "def extract_questions(message):\n",
    "    questions = []\n",
    "    regex_pattern = \" |\".join(questions_start_with)\n",
    "    for _string in message.lower().split(\"\\n\"):\n",
    "        if _string.endswith(\"?\"):\n",
    "            questions.append(_string)\n",
    "        else:\n",
    "            matches = re.findall(regex_pattern, _string.strip())\n",
    "            if len(matches) > 0:\n",
    "                split_str = _string.split()\n",
    "                if (\"vi\" in split_str[0] or \"vo\" in split_str[0]):\n",
    "                    first_word = split_str[1].strip()\n",
    "                    if first_word in string.punctuation:\n",
    "                        for i in range(2, len(split_str)):\n",
    "                            if split_str[i] not in string.punctuation and split_str[i] not in ['vo', 'vi']:\n",
    "                                first_word = split_str[i]\n",
    "                                break\n",
    "\n",
    "\n",
    "                else:\n",
    "                     first_word = split_str[0]\n",
    "                if first_word in questions_start_with:\n",
    "                    questions.append(_string)\n",
    "    return questions\n",
    "\n",
    "df_filter['Questions'] = df_filter['message'].apply(extract_questions)\n",
    "df_filter['Questions'].fillna(\"NA\", inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter.to_csv(\"Questions_extracted.csv\", index=False)"
   ]
  },
  {
   "source": [
    "### Extracting University Name\n",
    "<a id='extract_university'></a>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from multiprocessing import  Pool\n",
    "# from functools import partial\n",
    "# import numpy as np\n",
    "# # # Taken from here : https://stackoverflow.com/questions/26784164/pandas-multiprocessing-apply#:~:text=from%20multiprocessing%20import,run_on_subset%2C%20func)%2C%20num_of_processes)\n",
    "\n",
    "# def parallelize(data, func, num_of_processes=4):\n",
    "#     data_split = np.array_split(data, num_of_processes)\n",
    "#     pool = Pool(num_of_processes)\n",
    "#     data = pd.concat(pool.map(func, data_split))\n",
    "#     pool.close()\n",
    "#     pool.join()\n",
    "#     return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_unv = pd.read_excel('AccreditationData.xlsx', sheet_name='InstituteCampuses')\n",
    "\n",
    "# def update_parent_data(location_name, parent_name):\n",
    "#     if parent_name == '-':\n",
    "#         return location_name\n",
    "#     else:\n",
    "#         return parent_name\n",
    "\n",
    "# df_unv['UniqueName'] = df_unv.apply(lambda x: update_parent_data(x.LocationName, x.ParentName), axis=1)\n",
    "# unique_university_names = df_unv['UniqueName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10595\n"
     ]
    }
   ],
   "source": [
    "# print(len(unique_university_names))\n",
    "# There are 10595 unique universities across USA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fuzzywuzzy import fuzz\n",
    "\n",
    "# matchlist = ['hospital','university','institute','school','academy', 'unv', 'univ']\n",
    "\n",
    "# unv_regex_str = \"|\".join(matchlist)\n",
    "\n",
    "# def get_unv_name_from_text(message):\n",
    "#     split_str = message.split(\"\\n\")\n",
    "#     for _str in split_str:\n",
    "#         matches = re.findall(unv_regex_str, _str.strip())\n",
    "#         if len(matches) > 0:\n",
    "#             return _str\n",
    "    \n",
    "#     # max, max_index = -999999999, \"NA\"\n",
    "#     # for unv_index, _unv_name in enumerate(unique_university_names):\n",
    "#     #     str1, str2 = message, _unv_name\n",
    "#     #     token_set_ratio = fuzz.token_set_ratio(str1, str2)\n",
    "#     #     # token_set_ratio_list.append(token_set_ratio)\n",
    "#     #     if token_set_ratio > max:\n",
    "#     #         max = token_set_ratio\n",
    "#     #         max_index = unv_index\n",
    "#     #         # index = np.argmax(token_set_ratio_list)\n",
    "#     # try:\n",
    "#     #     return unique_university_names[max_index]\n",
    "#     # except Exception as e:\n",
    "#     return \"NA\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 2301/2301 [00:00<00:00, 20389.56it/s]\n",
      "/home/ubuntu/repos/f1_visa_interview/lib/python3.8/site-packages/pandas/core/frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n",
      "CPU times: user 282 ms, sys: 4 µs, total: 282 ms\n",
      "Wall time: 273 ms\n"
     ]
    }
   ],
   "source": [
    "# %%time\r\n",
    "# from tqdm import tqdm\r\n",
    "# tqdm.pandas()\r\n",
    "\r\n",
    "# df_filter[\"University_name\"] = df_filter['message'].progress_apply(get_unv_name_from_text)\r\n",
    "# df_filter.to_csv(\"UnvName_extracted.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/ubuntu/repos/f1_visa_interview/lib/python3.8/site-packages/pandas/core/frame.py:3607: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._set_item(key, value)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "MONTHDAY = r\"(?:(?:0[1-9])|(?:[12][0-9])|(?:3[01])|[1-9])\"\n",
    "MONTH = r\"\\b(?:jan(?:uary|uar)?|feb(?:ruary|ruar)?|m(?:a|ä)?r(?:ch|z)?|apr(?:il)?|ma(?:y|i)?|jun(?:e|i)?|jul(?:y)?|aug(?:ust)?|sep(?:tember)?|o(?:c|k)?t(?:ober)?|nov(?:ember)?|de(?:c|z)(?:ember)?)\\b\"\n",
    "\n",
    "unv_name = []\n",
    "visa_interview_date = []\n",
    "\n",
    "def get_organization_visa_date(message):\n",
    "    # print(unv_name, visa_interview_date)\n",
    "    doc = nlp(message)\n",
    "    final_dict = { entity.text:entity.label_  for entity in doc.ents}\n",
    "    # print(final_dict)\n",
    "    visa_date, u_name = None, None\n",
    "    for key, value in final_dict.items():\n",
    "        # print(visa_date, u_name)\n",
    "        if value == 'ORG' and \"university\" in key.lower() and \"research\" not in key.lower():\n",
    "            if u_name == None:\n",
    "                u_name = key\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        elif value == 'DATE' and re.findall(MONTH, key.lower()) and re.findall(MONTHDAY, key):\n",
    "            if visa_date == None:\n",
    "                visa_date = key\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            continue\n",
    "    visa_interview_date.append(visa_date)\n",
    "    unv_name.append(u_name)\n",
    "\n",
    "\n",
    "\n",
    "    # visa_date.append(final_dict.get('DATE'))\n",
    "\n",
    "for row in df_filter.itertuples():\n",
    "    get_organization_visa_date(row.message)\n",
    "# df_test['message'].apply(get_organization_visa_date)\n",
    "df_filter[\"University_name\"] = unv_name\n",
    "df_filter[\"VisaInterviewDate\"] = visa_interview_date\n",
    "df_filter.to_csv(\"FinalData.csv\", index=False)\n"
   ]
  },
  {
   "source": [
    "### Extracting Interview Date\n",
    "<a id='extract_interview_date'></a>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/ubuntu/repos/f1_visa_interview/lib/python3.8/site-packages/dateutil/parser/_parser.py:1213: UnknownTimezoneWarning: tzname OF identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n",
      "/home/ubuntu/repos/f1_visa_interview/lib/python3.8/site-packages/dateutil/parser/_parser.py:1213: UnknownTimezoneWarning: tzname M identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n",
      "/home/ubuntu/repos/f1_visa_interview/lib/python3.8/site-packages/dateutil/parser/_parser.py:1213: UnknownTimezoneWarning: tzname STAT identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n",
      "CPU times: user 17 s, sys: 6.81 ms, total: 17.1 s\n",
      "Wall time: 17 s\n",
      "/home/ubuntu/repos/f1_visa_interview/lib/python3.8/site-packages/pandas/core/frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import datefinder\n",
    "\n",
    "def extract_date_from_message(message):\n",
    "    try:\n",
    "        matches = list(datefinder.find_dates(message))\n",
    "        return matches[0]\n",
    "    except Exception as e:\n",
    "        return 'NA'\n",
    "\n",
    "\n",
    "df_filter['Visa Interview Date'] = df_filter['message'].apply(extract_date_from_message)\n",
    "df_filter.to_csv(\"Dates.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 102 ms, sys: 20.2 ms, total: 122 ms\nWall time: 119 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# from datetime import datetime\n",
    "\n",
    "# greater_than_date = datetime.strptime('2021-07-12', '%Y-%m-%d')\n",
    "# less_than_date = datetime.strptime('2020-01-01', '%Y-%m-%d')\n",
    "\n",
    "# def replace_value(visa_interview_date):\n",
    "#     try:\n",
    "#         final_vi_date = datetime.strptime(visa_interview_date.split(\" \")[0], '%Y-%m-%d')\n",
    "\n",
    "#         if (final_vi_date > greater_than_date) or (final_vi_date < less_than_date):\n",
    "#             return \"NA\"\n",
    "#         else:\n",
    "#             return visa_interview_date\n",
    "#     except Exception as e:\n",
    "#         return \"NA\"\n",
    "\n",
    "\n",
    "# df_filter['Visa Interview Date'] = df_filter['Visa Interview Date'].apply(replace_value)\n",
    "\n",
    "# df_filter['Visa Interview Date'] = df_filter['Visa Interview Date'].replace(pd.NaT, \"NA\")\n",
    "# df_filter['Visa Interview Date'] = pd.to_datetime(df_filter['Visa Interview Date'])\n",
    "\n",
    "# df_filter.loc[df_filter['Visa Interview Date'] > greater_than_date, \"Visa Interview Date\"] = \"NA\"\n",
    "# df_filter.loc[df_filter['Visa Interview Date'] < less_than_date, \"Visa Interview Date\"] = \"NA\"\n",
    "\n",
    "\n",
    "# def extract_dates_for_failed_messages(message, extracted_date):\n",
    "#     try:\n",
    "#         return dateparser.parse(str(extracted_date))\n",
    "#     except Exception as e:\n",
    "#         matches = search_dates(message)\n",
    "#         for match in matches:\n",
    "#             if today.month and today.year and today.day:\n",
    "#                 return match\n",
    "\n",
    "# df_filter['Visa Interview Date'] = df_filter.apply(lambda x : extract_dates_for_failed_messages(x['message'], x['Visa Interview Date']), axis=1)\n",
    "df_filter.to_csv(\"Final_Dates.csv\", index=False)           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"\"\" \"July 9th\n",
    "Hyderabad Consulate\n",
    "In time 10:25\n",
    "http://t.me/f1interviewreviews\n",
    "Out time 10:40\n",
    "University name: University of Connecticut\n",
    "Status: Approved (45 seconds max)\n",
    "Appointment time 11:00 AM\n",
    "Counter 12\n",
    "VO was a white American lady, super chill and very nicely spoken.\n",
    "2 other counters were open.\n",
    "\n",
    "Me: Good morning, Maâ€™am.\n",
    "VO: Good morning.\n",
    "VO: Please hold your passport through the screen this way (showed how to)\n",
    "Me: Held the passport\n",
    "VO: Can you please pass your I-20 from below the glass?\n",
    "Me: Passed I-20\n",
    "VO: When did you graduate?\n",
    "Me: I graduated in 2017\n",
    "VO: What did you do since then?\n",
    "Me: I was working in XXX MNC for the past 3.5 years as an analyst.\n",
    "VO: Thatâ€™s nice. What are you going to pursue in this University?\n",
    "Me: I am going to pursue Masters in Business Analytics.\n",
    "VO (typed for 10 seconds): Why this course?\n",
    "Me: Told\n",
    "VO: How are you sponsoring?\n",
    "Me: Told\n",
    "VO typed for 10 seconds. Looked at me and typed for another 5-10 seconds.\n",
    "\n",
    "VO: Take your I-20.\n",
    "She didnâ€™t speak anything for 5 seconds. I got scared for a while and was looking at her for her reply.\n",
    "VO: Drop your VISA in the box there. I'm approving your visa.\n",
    "Me: Thank you so much, Maâ€™am.\n",
    "VO: Have a good stay at USA. Have fun.\n",
    "Me: Thank you, Maâ€™am.\n",
    "She was as excited as I was after approving. Very nicely replied.\n",
    "@f1interviewreviews\"\n",
    "\n",
    "\n",
    "# \"\"\"\n",
    "# import re\n",
    "# questions = []\n",
    "\n",
    "# get_unv_name_from_text(txt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "July 9th DATE\nHyderabad Consulate PERSON\n10:25\nhttp://t.me/f1interviewreviews TIME\n10:40 TIME\nUniversity of Connecticut ORG\n45 seconds max TIME\n11:00 AM TIME\nAmerican NORP\n2 CARDINAL\nI-20 PRODUCT\n2017 DATE\nXXX ORG\nthe past 3.5 years DATE\n™ CARDINAL\nBusiness Analytics ORG\n10 seconds TIME\n10 seconds TIME\n5-10 seconds TIME\nI-20 DATE\ndidnâ€™ LAW\n5 seconds TIME\nVISA ORG\nUSA GPE\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load English tokenizer, tagger, parser and NER\n",
    "nlp = spacy.load('en')\n",
    "doc = nlp(txt)\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['7']"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "txt = 'may 7th'\n",
    "MONTHDAY = r\"(?:(?:0[1-9])|(?:[12][0-9])|(?:3[01])|[1-9])\"\n",
    "MONTH = r\"\\b(?:jan(?:uary|uar)?|feb(?:ruary|ruar)?|m(?:a|ä)?r(?:ch|z)?|apr(?:il)?|ma(?:y|i)?|jun(?:e|i)?|jul(?:y)?|aug(?:ust)?|sep(?:tember)?|o(?:c|k)?t(?:ober)?|nov(?:ember)?|de(?:c|z)(?:ember)?)\\b\"\n",
    "re.findall(MONTHDAY, txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}