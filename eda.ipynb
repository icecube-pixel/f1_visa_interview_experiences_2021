{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('f1_visa_interview')"
  },
  "interpreter": {
   "hash": "7319741835937c9a7ccb71e0c1799b3e850519b7bf6441da0617d4324770e27d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       sender_id                                            message\n",
       "0 -1001285729190  My Visa experience - 07/08/2021\\nApproved✅\\nDe...\n",
       "1 -1001285729190  9th July 2021\\nLocation: Hyderabad\\nAppointmen...\n",
       "2 -1001285729190  July 9th\\nHyderabad Consulate\\nIn time 10:25\\n...\n",
       "3 -1001285729190  9th July 2021\\nChennai VAC(July 4) and VI\\nApp...\n",
       "4 -1001285729190  Visa experience - 8/7/21 \\nApproved✅\\nMumbai c..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sender_id</th>\n      <th>message</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1001285729190</td>\n      <td>My Visa experience - 07/08/2021\\nApproved✅\\nDe...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-1001285729190</td>\n      <td>9th July 2021\\nLocation: Hyderabad\\nAppointmen...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1001285729190</td>\n      <td>July 9th\\nHyderabad Consulate\\nIn time 10:25\\n...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1001285729190</td>\n      <td>9th July 2021\\nChennai VAC(July 4) and VI\\nApp...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1001285729190</td>\n      <td>Visa experience - 8/7/21 \\nApproved✅\\nMumbai c...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df = pd.read_csv('Messages_text.csv')\n",
    "df.head()"
   ]
  },
  {
   "source": [
    "## Exploring messages\n",
    "\n",
    "* Its possible that we have empty cells and some jargon messages where the len of the message is < 145 characters.\n",
    "* Note: 145 is not a magic number. After observing messages where the character size < 145, i concluded that the information available was irrelavent. Hence the messages with < 145 characters are ignored. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2397, 2)\nShape of dataframe after dropping nan rows\n(2357, 2)\n"
     ]
    }
   ],
   "source": [
    "# Check for Nan values in messages column.\n",
    "df['message'].isnull().sum()\n",
    "print(df.shape) # (2397, 2)\n",
    "# As there are 40 null values, we can drop the rows as they are of no use\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "print(\"Shape of dataframe after dropping nan rows\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MESSAGES_LEN_TO_IGNORE = 145\n",
    "\n",
    "df['length_of_message'] = df['message'].apply(lambda x : len(str(x)))\n",
    "# Filter out of the rows with message length < 145\n",
    "df_filter = df[df['length_of_message'] > MESSAGES_LEN_TO_IGNORE]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2301, 3)\n"
     ]
    }
   ],
   "source": [
    "# The final dataframe after filtering out un-necessary messages \n",
    "print(df_filter.shape)"
   ]
  },
  {
   "source": [
    "## Below attributes will be extracted from messages\n",
    "* [Extracting Status](#extract_status)\n",
    "* [Extracting Visa Interview Date](#extract_interview_date)\n",
    "* [Extracting location](#extract_location)\n",
    "* [Extracting Questions asked in VI](#extract_questions)\n",
    "* [Extracting University Name](#extract_university)\n",
    "* ~~Duration~~\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Extracting location\n",
    "<a id='extract_location'></a>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/ubuntu/repos/f1_visa_interview/lib/python3.8/site-packages/pandas/core/frame.py:3607: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._set_item(key, value)\n"
     ]
    }
   ],
   "source": [
    "def get_consulate_location(str_to_check):\n",
    "    known_consulate_locations = ['hyderabad', 'mumbai', 'kolkata', 'delhi', 'chennai', 'hyd', 'bombay', 'malaysia', 'madras']\n",
    "    str_converted_to_lower = str_to_check.lower()\n",
    "    for consulate_location in known_consulate_locations:\n",
    "        if consulate_location in str_converted_to_lower:\n",
    "            return consulate_location\n",
    "\n",
    "\n",
    "df_filter['consulate_location'] = df_filter['message'].apply(get_consulate_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/ubuntu/repos/f1_visa_interview/lib/python3.8/site-packages/pandas/core/generic.py:6383: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  return self._update_inplace(result)\n"
     ]
    }
   ],
   "source": [
    "mapping_dict = {'bombay' : \"mumbai\", 'hyd' : \"hyderabad\", \"madras\" : \"chennai\"}\n",
    "df_filter['consulate_location'] = df_filter['consulate_location'].apply(lambda x : mapping_dict.get(x) if mapping_dict.get(x) is not None else x )\n",
    "df_filter['consulate_location'].fillna(\"NA\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mumbai       912\ndelhi        534\nchennai      340\nhyderabad    302\nkolkata      158\nNA            54\nmalaysia       1\nName: consulate_location, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_filter.consulate_location.value_counts())\n",
    "df_filter.to_csv(\"Test.csv\", index=False)"
   ]
  },
  {
   "source": [
    "### Extracting Status \n",
    "<a id='extract_status'></a>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_visa_status(message):\n",
    "    possible_status = ['approved', 'rejected']\n",
    "    for _status in possible_status:\n",
    "        if _status in message.lower():\n",
    "            return _status\n",
    "\n",
    "df_filter['visa_status'] = df_filter['message'].apply(get_visa_status)\n",
    "df_filter['visa_status'].fillna(\"NA\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "approved    2027\n",
       "rejected     200\n",
       "NA            74\n",
       "Name: visa_status, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "df_filter['visa_status'].value_counts()"
   ]
  },
  {
   "source": [
    "### Extracting Questions\n",
    "<a id='extract_questions'></a>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/ubuntu/repos/f1_visa_interview/lib/python3.8/site-packages/pandas/core/frame.py:3607: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._set_item(key, value)\n/home/ubuntu/repos/f1_visa_interview/lib/python3.8/site-packages/pandas/core/generic.py:6383: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  return self._update_inplace(result)\n"
     ]
    }
   ],
   "source": [
    "questions_start_with = ['what', 'what\\'s', 'which', 'who', 'where', 'why', 'when', 'how', 'whose', 'do', 'are', 'will', 'did ']\n",
    "\n",
    "import re\n",
    "import string \n",
    "\n",
    "\n",
    "def extract_questions(message):\n",
    "    questions = []\n",
    "    regex_pattern = \" |\".join(questions_start_with)\n",
    "    for _string in message.lower().split(\"\\n\"):\n",
    "        if _string.endswith(\"?\"):\n",
    "            questions.append(_string)\n",
    "        else:\n",
    "            matches = re.findall(regex_pattern, _string.strip())\n",
    "            if len(matches) > 0:\n",
    "                split_str = _string.split()\n",
    "                if (\"vi\" in split_str[0] or \"vo\" in split_str[0]):\n",
    "                    first_word = split_str[1].strip()\n",
    "                    if first_word in string.punctuation:\n",
    "                        for i in range(2, len(split_str)):\n",
    "                            if split_str[i] not in string.punctuation and split_str[i] not in ['vo', 'vi']:\n",
    "                                first_word = split_str[i]\n",
    "                                break\n",
    "\n",
    "\n",
    "                else:\n",
    "                     first_word = split_str[0]\n",
    "                if first_word in questions_start_with:\n",
    "                    questions.append(_string)\n",
    "    return questions\n",
    "\n",
    "df_filter['Questions'] = df_filter['message'].apply(extract_questions)\n",
    "df_filter['Questions'].fillna(\"NA\", inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter.to_csv(\"Questions_extracted.csv\", index=False)"
   ]
  },
  {
   "source": [
    "### Extracting University Name\n",
    "<a id='extract_university'></a>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import  Pool\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "# Taken from here : https://stackoverflow.com/questions/26784164/pandas-multiprocessing-apply#:~:text=from%20multiprocessing%20import,run_on_subset%2C%20func)%2C%20num_of_processes)\n",
    "\n",
    "def parallelize(data, func, num_of_processes=4):\n",
    "    data_split = np.array_split(data, num_of_processes)\n",
    "    pool = Pool(num_of_processes)\n",
    "    data = pd.concat(pool.map(func, data_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unv = pd.read_excel('AccreditationData.xlsx', sheet_name='InstituteCampuses')\n",
    "\n",
    "def update_parent_data(location_name, parent_name):\n",
    "    if parent_name == '-':\n",
    "        return location_name\n",
    "    else:\n",
    "        return parent_name\n",
    "\n",
    "df_unv['UniqueName'] = df_unv.apply(lambda x: update_parent_data(x.LocationName, x.ParentName), axis=1)\n",
    "unique_university_names = df_unv['UniqueName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10595\n"
     ]
    }
   ],
   "source": [
    "print(len(unique_university_names))\n",
    "# There are 10595 unique universities across USA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matchlist = ['Hospital','University','Institute','School','Academy', 'Unv']\n",
    "# matchlist_lower_case = [pattern.lower() for pattern in matchlist]\n",
    "# final_patterns_to_check = matchlist_lower_case + matchlist\n",
    "\n",
    "# regex_str = \"\"\"[A-Z][^\\\\.;\\\\?\\\\!]*(\\\\b{regex_str}\\\\b)[^\\\\.;\\\\?\\\\!]*\"\"\".format(regex_str = \"\\\\b|\\\\b\".join(final_patterns_to_check))\n",
    "# print(regex_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processing 25 rowProcessing 50 rowProcessing 0 rowProcessing 75 row\n",
      "\n",
      "\n",
      "\n",
      "Total time taken: 15.823212385177612 sec\n",
      "Processing 51 row\n",
      "Total time taken: 23.171153783798218 sec\n",
      "Processing 76 row\n",
      "Total time taken: 27.08977723121643 sec\n",
      "Processing 26 row\n",
      "Total time taken: 14.865477085113525 sec\n",
      "Processing 77 row\n",
      "Total time taken: 39.20491814613342 sec\n",
      "Processing 1 row\n",
      "Total time taken: 21.461410760879517 sec\n",
      "Processing 27 row\n",
      "Total time taken: 17.971954345703125 sec\n",
      "Processing 2 row\n",
      "Total time taken: 21.624213457107544 sec\n",
      "Processing 78 row\n",
      "Total time taken: 46.52960181236267 sec\n",
      "Processing 52 row\n",
      "Total time taken: 20.068583965301514 sec\n",
      "Processing 28 row\n",
      "Total time taken: 29.28138780593872 sec\n",
      "Processing 3 row\n",
      "Total time taken: 35.054041624069214 sec\n",
      "Processing 79 row\n",
      "Total time taken: 29.050139904022217 sec\n",
      "Processing 29 row\n",
      "Total time taken: 42.27673888206482 sec\n",
      "Processing 53 row\n",
      "Total time taken: 14.049971580505371 sec\n",
      "Processing 80 row\n",
      "Total time taken: 31.607022523880005 sec\n",
      "Processing 4 row\n",
      "Total time taken: 29.940982818603516 sec\n",
      "Processing 54 row\n",
      "Total time taken: 24.25055432319641 sec\n",
      "Processing 5 row\n",
      "Total time taken: 35.440768241882324 sec\n",
      "Processing 81 row\n",
      "Total time taken: 56.942387104034424 sec\n",
      "Processing 30 row\n",
      "Total time taken: 27.761003732681274 sec\n",
      "Processing 55 row\n",
      "Total time taken: 23.13686203956604 sec\n",
      "Processing 82 row\n",
      "Total time taken: 36.56887888908386 sec\n",
      "Processing 6 row\n",
      "Total time taken: 26.789811849594116 sec\n",
      "Processing 31 row\n",
      "Total time taken: 22.010809421539307 sec\n",
      "Processing 83 row\n",
      "Total time taken: 34.12027668952942 sec\n",
      "Processing 56 row\n",
      "Total time taken: 23.511869430541992 sec\n",
      "Processing 7 row\n",
      "Total time taken: 28.43105721473694 sec\n",
      "Processing 32 row\n",
      "Total time taken: 27.954492568969727 sec\n",
      "Processing 84 row\n",
      "Total time taken: 31.204223155975342 sec\n",
      "Processing 57 row\n",
      "Total time taken: 31.250634908676147 sec\n",
      "Processing 8 row\n",
      "Total time taken: 24.73068356513977 sec\n",
      "Processing 33 row\n",
      "Total time taken: 21.87780499458313 sec\n",
      "Processing 58 row\n",
      "Total time taken: 33.269805908203125 sec\n",
      "Processing 85 row\n",
      "Total time taken: 18.626856803894043 sec\n",
      "Processing 9 row\n",
      "Total time taken: 19.885241746902466 sec\n",
      "Processing 10 row\n",
      "Total time taken: 40.916287660598755 sec\n",
      "Processing 34 row\n",
      "Total time taken: 28.102715253829956 sec\n",
      "Processing 86 row\n",
      "Total time taken: 41.21487045288086 sec\n",
      "Processing 59 row\n",
      "Total time taken: 24.11655306816101 sec\n",
      "Processing 87 row\n",
      "Process ForkPoolWorker-41:\n",
      "Process ForkPoolWorker-44:\n",
      "Process ForkPoolWorker-42:\n",
      "Process ForkPoolWorker-43:\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2877/1867824664.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total time taken: {sec} sec\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mmaster_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mdf_merge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparallelize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_filter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_university_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# df_filter['University Name'] = df_filter['message'].apply(get_university_name)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2877/1031822732.py\u001b[0m in \u001b[0;36mparallelize\u001b[0;34m(data, func, num_of_processes)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdata_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_of_processes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_of_processes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         '''\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "import time\n",
    "# https://www.datacamp.com/community/tutorials/fuzzy-string-python\n",
    "# https://www.geeksforgeeks.org/how-to-do-fuzzy-matching-on-pandas-dataframe-column-using-python/ - Explore more\n",
    "\n",
    "master_data = []\n",
    "\n",
    "def get_university_name(df):\n",
    "    \n",
    "    for index, row_data in df.iterrows():\n",
    "        print(\"Processing {index} row\".format(index=index))\n",
    "        start = time.time()\n",
    "        row = row_data.to_dict()\n",
    "        max, max_index = 0, 'na'\n",
    "        for unv_index, _unv_name in enumerate(unique_university_names):\n",
    "            str1, str2 = row.get('message'), _unv_name\n",
    "            token_set_ratio = fuzz.token_set_ratio(str1, str2)\n",
    "            # token_set_ratio_list.append(token_set_ratio)\n",
    "            if token_set_ratio > max:\n",
    "                max = token_set_ratio\n",
    "                max_index = unv_index\n",
    "        # index = np.argmax(token_set_ratio_list)\n",
    "        row['university_name'] = unique_university_names[max_index]\n",
    "        end = time.time()\n",
    "        print(\"Total time taken: {sec} sec\".format(sec=str(end-start)))\n",
    "        master_data.append(row)\n",
    "df_merge = parallelize(df_filter.head(100), get_university_name)\n",
    "\n",
    "# df_filter['University Name'] = df_filter['message'].apply(get_university_name)"
   ]
  },
  {
   "source": [
    "### Extracting Interview Date\n",
    "<a id='extract_interview_date'></a>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/ubuntu/repos/f1_visa_interview/lib/python3.8/site-packages/dateutil/parser/_parser.py:1213: UnknownTimezoneWarning: tzname OF identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n",
      "/home/ubuntu/repos/f1_visa_interview/lib/python3.8/site-packages/dateutil/parser/_parser.py:1213: UnknownTimezoneWarning: tzname M identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n",
      "/home/ubuntu/repos/f1_visa_interview/lib/python3.8/site-packages/dateutil/parser/_parser.py:1213: UnknownTimezoneWarning: tzname STAT identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n",
      "CPU times: user 17 s, sys: 6.81 ms, total: 17.1 s\n",
      "Wall time: 17 s\n",
      "/home/ubuntu/repos/f1_visa_interview/lib/python3.8/site-packages/pandas/core/frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import datefinder\n",
    "\n",
    "def extract_date_from_message(message):\n",
    "    try:\n",
    "        matches = list(datefinder.find_dates(message))\n",
    "        return matches[0]\n",
    "    except Exception as e:\n",
    "        return 'NA'\n",
    "\n",
    "\n",
    "df_filter['Visa Interview Date'] = df_filter['message'].apply(extract_date_from_message)\n",
    "df_filter.to_csv(\"Dates.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 102 ms, sys: 20.2 ms, total: 122 ms\nWall time: 119 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# from datetime import datetime\n",
    "\n",
    "# greater_than_date = datetime.strptime('2021-07-12', '%Y-%m-%d')\n",
    "# less_than_date = datetime.strptime('2020-01-01', '%Y-%m-%d')\n",
    "\n",
    "# def replace_value(visa_interview_date):\n",
    "#     try:\n",
    "#         final_vi_date = datetime.strptime(visa_interview_date.split(\" \")[0], '%Y-%m-%d')\n",
    "\n",
    "#         if (final_vi_date > greater_than_date) or (final_vi_date < less_than_date):\n",
    "#             return \"NA\"\n",
    "#         else:\n",
    "#             return visa_interview_date\n",
    "#     except Exception as e:\n",
    "#         return \"NA\"\n",
    "\n",
    "\n",
    "# df_filter['Visa Interview Date'] = df_filter['Visa Interview Date'].apply(replace_value)\n",
    "\n",
    "# df_filter['Visa Interview Date'] = df_filter['Visa Interview Date'].replace(pd.NaT, \"NA\")\n",
    "# df_filter['Visa Interview Date'] = pd.to_datetime(df_filter['Visa Interview Date'])\n",
    "\n",
    "# df_filter.loc[df_filter['Visa Interview Date'] > greater_than_date, \"Visa Interview Date\"] = \"NA\"\n",
    "# df_filter.loc[df_filter['Visa Interview Date'] < less_than_date, \"Visa Interview Date\"] = \"NA\"\n",
    "\n",
    "\n",
    "# def extract_dates_for_failed_messages(message, extracted_date):\n",
    "#     try:\n",
    "#         return dateparser.parse(str(extracted_date))\n",
    "#     except Exception as e:\n",
    "#         matches = search_dates(message)\n",
    "#         for match in matches:\n",
    "#             if today.month and today.year and today.day:\n",
    "#                 return match\n",
    "\n",
    "# df_filter['Visa Interview Date'] = df_filter.apply(lambda x : extract_dates_for_failed_messages(x['message'], x['Visa Interview Date']), axis=1)\n",
    "df_filter.to_csv(\"Final_Dates.csv\", index=False)           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "why usa?\nwhat did you do in undergraduate?\nhow you going to fund?\n"
     ]
    }
   ],
   "source": [
    "txt = \"\"\" \"VISA : REJECTED âŒ\n",
    "Location: New Delhi\n",
    "Slot time: 10:30\n",
    "In-time: 9:30AM\n",
    "Out-time: 10:05 AM\n",
    "Counter : 21\n",
    "http://t.me/f1interviewreviews\n",
    "\n",
    "Troy University\n",
    "\n",
    "Only four to five counters were open.\n",
    "\n",
    "Duration: around 2 minutes\n",
    "\n",
    "VO is Asian American  guy in his 30â€™s\n",
    "\n",
    "good morning pass me your passport, i20 and sevis fee receipt\n",
    "good morning sir, how are you  (passed)\n",
    "i am doing good, Thank you.\n",
    "place your right hand four finger on scanner.\n",
    "did \n",
    "\n",
    "why usa?\n",
    "Sir i want to pursue my masterâ€™s in computer science with specialisation in software development\n",
    "Typing for 30-40 seconds and look towards i-20\n",
    "\n",
    "what did you do in undergraduate?\n",
    "i have completed my bachelors in computer science and engineering from charusat university, recently in 2021\n",
    "\n",
    "\n",
    "how you going to fund?\n",
    "My parents are going to sponsor me.My father has a savings of 35 lakhs rupees in his savings account which equivalent to 47 thousand USD and apart from that we have a immovable assets worth 1.27 crores which is equivalent to 1.7 lakh USD \n",
    "\n",
    "Typing for 20-25 seconds \n",
    "\n",
    "\n",
    "Vo: Unfortunately i am not approving your visa.\n",
    "\n",
    "\n",
    "@f1interviewreviews\"\n",
    "\n",
    "\"\"\"\n",
    "import re\n",
    "questions = []\n",
    "\n",
    "regex_pattern = \" |\".join(questions_start_with)\n",
    "for _string in txt.lower().split(\"\\n\"):\n",
    "    if _string.endswith(\"?\"):\n",
    "        questions.append(_string)\n",
    "    else:\n",
    "        matches = re.findall(regex_pattern, _string.strip())\n",
    "        if len(matches) > 0:\n",
    "            split_str = _string.split()\n",
    "            first_word = split_str[1] if \"vi\" in split_str[0] else split_str[0]\n",
    "            if first_word in questions_start_with:\n",
    "                questions.append(_string)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: nltk in /home/ubuntu/repos/f1_visa_interview/lib/python3.8/site-packages (3.6.2)\n",
      "Requirement already satisfied: joblib in /home/ubuntu/repos/f1_visa_interview/lib/python3.8/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: regex in /home/ubuntu/repos/f1_visa_interview/lib/python3.8/site-packages (from nltk) (2021.7.6)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/repos/f1_visa_interview/lib/python3.8/site-packages (from nltk) (4.61.2)\n",
      "Requirement already satisfied: click in /home/ubuntu/repos/f1_visa_interview/lib/python3.8/site-packages (from nltk) (7.1.2)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}